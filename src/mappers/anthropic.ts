import {
	AnthropicContentBlock,
	AnthropicMessage,
	AnthropicRequest,
	AnthropicToolDef,
	ChatCompletionRequest,
	OAIMessage,
} from "../types";
import { clamp, DEFAULT_MAX_TOKENS, selectMaxTokens } from "../utils/tokens";

export function stripAnthropicDateSuffix(model: string): string {
	if(model === "claude-sonnet-4-5-20250929") {
		return "claude-sonnet-4-5";
	}
	return model;
	// return (model || "").replace(/-\d{8}$/, "");
}

function ensureHasUserMessage(messages: OAIMessage[]): boolean {
	return messages.some((m) => m.role === "user");
}

function normalizeContentToText(content: any): { text: string; changed: boolean } {
	if (typeof content === "string") return { text: content, changed: false };
	if (Array.isArray(content)) {
		const texts: string[] = [];
		for (const part of content) {
			if (part && typeof part === "object" && part.type === "text" && typeof part.text === "string") {
				texts.push(part.text);
			}
		}
		return { text: texts.join(""), changed: true };
	}
	return { text: String(content ?? ""), changed: true };
}

function mapOpenAIToolsToAnthropic(tools: any[] | null | undefined): AnthropicToolDef[] | undefined {
	if (!Array.isArray(tools) || tools.length === 0) return undefined;
	const out: AnthropicToolDef[] = [];
	for (const t of tools) {
		try {
			if (t && (t.type === "function" || t.function)) {
				const fn = t.function ?? {};
				const name = fn.name ?? t.name;
				if (typeof name !== "string" || name.length === 0) continue;
				const description = typeof fn.description === "string" ? fn.description : t.description;
				const input_schema = fn.parameters ?? { type: "object" };
				out.push({ name, description, input_schema });
			}
		} catch {
			// ignore malformed tool
		}
	}
	return out.length > 0 ? out : undefined;
}

function toAnthropicMessagesWithTools(req: ChatCompletionRequest): {
	system?: string;
	messages: AnthropicMessage[];
	hadAnyToolsSignal: boolean;
	anthropicTools?: AnthropicToolDef[];
} {
	let systemText: string | undefined = req.system ?? undefined;
	const messages: AnthropicMessage[] = [];
	const anthropicTools = mapOpenAIToolsToAnthropic(req.tools);
	let hadAnyToolsSignal = Array.isArray(req.tools) && req.tools.length > 0;

	for (const raw of req.messages || []) {
		const msg: any = raw as any;
		const role: string = msg.role;
		// Role meanings:
		// - "system": Special system-level instructions provided to the model, used for context/guidance.
		// - "user": A standard message from the user to the model.
		// - "assistant": A response from the AI assistant ("the model"), which may be either a direct message (text)
		//                or a request to invoke a tool/function (a "tool call") or both.
		// - "tool": The result/response from a tool/function after the assistant requested it.
		//
		// Difference between "assistant" and "tool"/tool call:
		//   * An "assistant" message is a reply generated by the model. It can be plain text, or can include
		//     one or more "tool calls", where the assistant asks for external tools or functions to be run
		//     (example: "function_call": { ... }). "assistant" messages may include both plain text and tool calls.
		//   * A "tool" message is the user-supplied result of a previously requested tool/function call â€“ 
		//     typically this is populated with the output after a tool has executed, and is passed back to the model
		//     for further processing/response. In Anthropic, tool results are placed as "tool_result" blocks
		//     under the user role.

		if (role === "system") {
			// "system": Given as Anthropic's system prompt, not a part of the conversation messages.
			if (!systemText) {
				const norm = normalizeContentToText(msg.content);
				systemText = norm.text;
			}
			continue;
		}

		if (role === "assistant") {
			// "assistant": Either plain text (model output) or tool call(s), or both.
			const toolCalls: any[] | undefined = Array.isArray(msg.tool_calls) ? msg.tool_calls : undefined;
			if (toolCalls && toolCalls.length > 0) {
				// This assistant message issues one or more tool/function calls.
				hadAnyToolsSignal = true;
				const blocks: AnthropicContentBlock[] = [];
				const norm = normalizeContentToText(msg.content);
				if (norm.text && norm.text.trim().length > 0) {
					blocks.push({ type: "text", text: norm.text });
				}
				for (const tc of toolCalls) {
					const id: string =
						typeof tc.id === "string" && tc.id.length > 0 ? tc.id : `toolu_${Math.random().toString(36).slice(2, 10)}`;
					const name: string = tc.function?.name ?? tc.name;
					let input: any = {};
					const argStr = tc.function?.arguments ?? tc.arguments;
					if (typeof argStr === "string") {
						try {
							input = JSON.parse(argStr);
						} catch {
							input = { __raw: argStr };
						}
					} else if (argStr && typeof argStr === "object") {
						input = argStr;
					}
					if (typeof name === "string" && name.length > 0) {
						blocks.push({ type: "tool_use", id, name, input });
					}
				}
				messages.push({ role: "assistant", content: blocks });
				continue;
			}
			const norm = normalizeContentToText(msg.content);
			messages.push({ role: "assistant", content: norm.text });
			continue;
		}

		if (role === "tool") {
			// "tool": Output/result from an external function/tool, to be consumed by the model in the next step.
			hadAnyToolsSignal = true;
			const toolUseId: string | undefined = msg.tool_call_id || msg.tool_call_id?.toString?.();
			const norm = normalizeContentToText(msg.content);
			const block: AnthropicContentBlock = {
				type: "tool_result",
				tool_use_id: toolUseId ?? "",
				content: norm.text ? [{ type: "text", text: norm.text }] : undefined,
			};
			// Tool results are mapped as "user" messages with tool_result content for Anthropic.
			messages.push({ role: "user", content: [block] });
			continue;
		}

		if (role === "user") {
			// "user": User's conversational turn.
			const norm = normalizeContentToText(msg.content);
			messages.push({ role: "user", content: norm.text });
			continue;
		}
	}

	return { system: systemText, messages, hadAnyToolsSignal, anthropicTools };
}

function extractSystemAndFilterMessages(req: ChatCompletionRequest): {
	system?: string;
	filtered: AnthropicMessage[];
	hadTools: boolean;
} {
	const providedSystem = req.system ?? undefined;
	let systemText = providedSystem;
	const filtered: AnthropicMessage[] = [];
	const hadTools = Array.isArray(req.tools) && req.tools.length > 0;

	for (const msg of req.messages || []) {
		if (msg.role === "system") {
			if (!systemText) {
				const norm = normalizeContentToText((msg as any).content);
				systemText = norm.text;
			}
			continue;
		}
		if (msg.role === "tool") {
			continue;
		}
		if (msg.role === "user" || msg.role === "assistant") {
			const norm = normalizeContentToText((msg as any).content);
			filtered.push({ role: msg.role, content: norm.text });
		}
	}
	return { system: systemText, filtered, hadTools };
}

export function mapOAItoAnthropic(req: ChatCompletionRequest): { request: AnthropicRequest; warnIgnoredTools: boolean } {
	if (!req || typeof req !== "object") {
		throw new Error("Invalid request body");
	}
	if (!Array.isArray(req.messages) || typeof req.model !== "string") {
		throw new Error("Missing required fields: model, messages");
	}
	const conv = toAnthropicMessagesWithTools(req);
	if (
		!ensureHasUserMessage(
			(conv.messages as any as OAIMessage[]).map((m: any) => {
				return { role: m.role, content: typeof m.content === "string" ? m.content : "" } as OAIMessage;
			}),
		)
	) {
		throw new Error("At least one user message is required");
	}
	const temperature = req.temperature !== null && req.temperature !== undefined ? clamp(req.temperature, 0, 2) : undefined;
	const maxTokens = selectMaxTokens(req, "anthropic") ?? DEFAULT_MAX_TOKENS;
	const stop_sequences = Array.isArray(req.stop) && req.stop.length > 0 ? req.stop.slice(0) : undefined;
	const stream = req.stream === null || req.stream === undefined ? true : Boolean(req.stream);
	const mappedModel = stripAnthropicDateSuffix(req.model);
	console.log(` lololno toolsmappedModel=${mappedModel} for request ${JSON.stringify(req)}`);
	return {
		request: {
			model: mappedModel,
			system: conv.system,
			messages: conv.messages,
			max_tokens: maxTokens,
			temperature,
			stop_sequences,
			stream,
			tools: conv.anthropicTools,
			thinking: (req as any)?.thinking ? { type: "enabled", ...(req as any).thinking } : undefined,
		},
		warnIgnoredTools: false,
	};
}

export function mapOAItoAnthropicNoTools(req: ChatCompletionRequest): { request: AnthropicRequest; warnIgnoredTools: boolean } {
	if (!req || typeof req !== "object") {
		throw new Error("Invalid request body");
	}
	if (!Array.isArray(req.messages) || typeof req.model !== "string") {
		throw new Error("Missing required fields: model, messages");
	}
	const { system, filtered } = extractSystemAndFilterMessages({
		...req,
		tools: undefined,
	} as ChatCompletionRequest);
	if (
		!ensureHasUserMessage(
			(filtered as any as OAIMessage[]).map((m: any) => {
				return { role: m.role, content: typeof m.content === "string" ? m.content : "" } as OAIMessage;
			}),
		)
	) {
		throw new Error("At least one user message is required");
	}
	const temperature = req.temperature !== null && req.temperature !== undefined ? clamp(req.temperature, 0, 2) : undefined;
	const maxTokens = selectMaxTokens(req, "anthropic") ?? DEFAULT_MAX_TOKENS;
	const stop_sequences = Array.isArray(req.stop) && req.stop.length > 0 ? req.stop.slice(0) : undefined;
	const stream = req.stream === null || req.stream === undefined ? true : Boolean(req.stream);
	const mappedModel = stripAnthropicDateSuffix(req.model);
	const ignored = Array.isArray((req as any).tools) && (req as any).tools.length > 0;
	console.log(` lololno notoolsmappedModel=${mappedModel} for request ${JSON.stringify(req)}`);

	return {
		request: {
			model: mappedModel,
			system,
			messages: filtered,
			max_tokens: maxTokens,
			temperature,
			stop_sequences,
			stream,
			tools: undefined,
			thinking: (req as any)?.thinking ? { type: "enabled", ...(req as any).thinking } : undefined,
		},
		warnIgnoredTools: ignored,
	};
}


